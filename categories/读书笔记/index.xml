<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>读书笔记 on A lifelong learner.</title>
    <link>https://egolearner.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link>
    <description>Recent content in 读书笔记 on A lifelong learner.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 10 Sep 2024 19:31:31 +0800</lastBuildDate><atom:link href="https://egolearner.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Memory Consistency</title>
      <link>https://egolearner.github.io/post/memory-consistency/</link>
      <pubDate>Tue, 10 Sep 2024 19:31:31 +0800</pubDate>
      
      <guid>https://egolearner.github.io/post/memory-consistency/</guid>
      <description>&lt;h1 id=&#34;a-primer-on-memory-consistency-and-cache-coherence&#34;&gt;A Primer on Memory Consistency and Cache Coherence&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;书籍信息
&lt;ul&gt;
&lt;li&gt;链接
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://book.douban.com/subject/35125808/&#34;&gt;A Primer on Memory Consistency and Cache Coherence (豆瓣) (douban.com)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;作者&lt;/li&gt;
&lt;li&gt;题材/主题&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;我为什么读这本书？
&lt;ul&gt;
&lt;li&gt;学习memory order&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;阅读前问题&lt;/li&gt;
&lt;li&gt;阅读中问题&lt;/li&gt;
&lt;li&gt;阅读时的思考&lt;/li&gt;
&lt;li&gt;主要内容&lt;/li&gt;
&lt;li&gt;本文提到的其他书籍&lt;/li&gt;
&lt;li&gt;评价
&lt;ul&gt;
&lt;li&gt;优点&lt;/li&gt;
&lt;li&gt;缺点&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;chap1-introduction-to-consistency-and-coherence&#34;&gt;Chap1 Introduction to Consistency and Coherence&lt;/h2&gt;
&lt;p&gt;Consistency的定义提供了load和store的规则以及它们如何作用于内存。&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h1 id="a-primer-on-memory-consistency-and-cache-coherence">A Primer on Memory Consistency and Cache Coherence</h1>
<ul>
<li>书籍信息
<ul>
<li>链接
<ul>
<li><a href="https://book.douban.com/subject/35125808/">A Primer on Memory Consistency and Cache Coherence (豆瓣) (douban.com)</a></li>
</ul>
</li>
<li>作者</li>
<li>题材/主题</li>
</ul>
</li>
<li>我为什么读这本书？
<ul>
<li>学习memory order</li>
</ul>
</li>
<li>阅读前问题</li>
<li>阅读中问题</li>
<li>阅读时的思考</li>
<li>主要内容</li>
<li>本文提到的其他书籍</li>
<li>评价
<ul>
<li>优点</li>
<li>缺点</li>
</ul>
</li>
</ul>
<h2 id="chap1-introduction-to-consistency-and-coherence">Chap1 Introduction to Consistency and Coherence</h2>
<p>Consistency的定义提供了load和store的规则以及它们如何作用于内存。</p>
<p>Coherence至于于让共享内存系统的Cache像单核系统上的Cache一样透明，使用将一个处理器的写入广播到其他处理器的方式。Consistency属于定义共享内存正确性的架构规范，而coherence是支撑consistency模型的一种方式。</p>
<p>对于特定输入的多线程程序，内存模型规定了dynamic load可以返回的值，可选的规定了内存最终的可能状态。通常允许多线程程序有多个正确的行为。</p>
<ul>
<li>Sequential Consistency(SC)中，多线程程序看起来像其中每个线程的交替执行，就像所有线程在单核机器上分时复用一样。</li>
<li>Total Store Order(TSO)，在将结果写入Cache前，使用FIFO的write buffer来保存committed store的结果。相比SC有更好的性能。</li>
<li>Relaxed or Weak Model，动机在于大部分强模型中的内存顺序是不必要的。例如，修改10个数据项和1个同步标记，10个数据项具体的内存顺序是不重要的，只需要保证在同步标记之前修改即可。</li>
</ul>
<p>在多核同时访问数据的多个副本，且至少有一个访问是写操作时会有coherence问题。使用coherence协议来避免访问到过期数据。通过广播操作使得一个处理器的写操作对其他处理器的Cache可见。目前基本是同步广播，异步广播机制正在出现。</p>
<ul>
<li><input disabled="" type="checkbox"> Database Replication. Synthesis Lectures on Data Management</li>
<li><input disabled="" type="checkbox"> Quorum Systems: With Applications to Storage and Consensus. Synthesis Lectures on Distributed Computing Theory</li>
</ul>
<h2 id="chap2-coherence-基础">Chap2 Coherence 基础</h2>
<p>在多种角色访问Cache和Memory时有coherence问题，如处理器、DMA、其他设备。</p>
<ul>
<li>
<p>Consistency-agnostic coherence。使用同步写，写操作在返回前对所有核可见，提供的接口和（不带Cache的）atomic memory system相同。</p>
<ul>
<li>single-writer-multiple-reader(SWMR)不变式。
<ul>
<li>另一种方式，使用token对SWMR不变式来解释。token个数和核数相等，拿到所有token时，可以执行写操作；拿到一个或多个token时，可以执行读操作。</li>
</ul>
</li>
<li>还要求给定内存的值被正确的广播，即数据值不变式：某个epoch开始时的值，等于上一个read-write epoch结束时的值。</li>
</ul>
<blockquote>
<p>Coherence invariants</p>
<ol>
<li>Single-Writer, Multiple-Read (SWMR) Invariant. For any memory location A, at any given time, there exists only a single core that may write to A (and can also read it) or some number of cores that may only read A.</li>
<li>Data-Value Invariant. The value of the memory location at the start of an epoch is the same as the value of the memory location at the end of the its last read-write epoch.</li>
</ol>
</blockquote>
</li>
<li>
<p>Consistency-directed coherence。写操作异步广播，coherence协议保证写操作以consistency模型强制的顺序最终可见，用以支持GP-GPU。</p>
</li>
</ul>
<p>Coherence的单位为cache block（例如cache line）。</p>
<h2 id="chap3-memory-consistency-motivation-and-sequential-consistency">Chap3 Memory Consistency Motivation and Sequential Consistency</h2>
<p>Reorder的类型</p>
<ul>
<li>Store-store reordering。如果核有非FIFO的write buffer可能会出现store-store reordering，第一个store miss而第二个store命中cache，或者第二个store可以和更早的store合并。</li>
<li>Load-load reordering。</li>
<li>Load-store和store-load reordering。
<ul>
<li>store-load reordering可能由于本地跳过了FIFO的write buffer。</li>
</ul>
</li>
</ul>
<table>
  <thead>
      <tr>
          <th style="text-align: left">Core C1</th>
          <th style="text-align: left">Core C2</th>
          <th style="text-align: left">Comments</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: left">S1: x = NEW;</td>
          <td style="text-align: left">S2: y = NEW;</td>
          <td style="text-align: left">/* Initially, x = 0 &amp; y = 0 */</td>
      </tr>
      <tr>
          <td style="text-align: left">L1: r1 = y;</td>
          <td style="text-align: left">L2: r2 = x;</td>
          <td style="text-align: left"></td>
      </tr>
  </tbody>
</table>
<p>大多数实际的硬件，包括x86，允许r1=0, r2=0作为最终的结果，因为它使用了FIFO的write buffer来提高性能。</p>
<p>memory model是共享内存使用共享内存执行的多线程程序允许的行为的规范。</p>
<ul>
<li>Cache coherence does not equal memory consistency.</li>
<li>A memory consistency implementation can use cache coherence as a useful “black box.”</li>
</ul>
<h3 id="sequential-consistencysc">Sequential Consistency(SC)</h3>
<p>SC最早由Lamport形式化，单核上的SC和Program Order相同，多核上的SC，如果所有核上的操作以某种顺序执行，序列中每个核的操作和Program Order相同。SC中，memory order遵循每个核上的Program Order，而其他的consistency model允许不遵守Program Order的memory order。</p>
<p>定义&lt;m为memory order, &lt;p为program order。在SC中，memory order遵守program order，即op1 &lt;p op2意味着op1 &lt;m op2。</p>
<p>3.5 SC的的规范化定义</p>
<p>L(a)和S(a)为对内存地址a的load和store操作。&lt;p为每个核上的total order，&lt;m为global memory order。</p>
<ol>
<li>所有的核将它们的load和store插入到&lt;m中，遵守其program order，无论是否是相同的地址。四种情况：
<ol>
<li>If L(a) &lt;p L(b) ⇒ L(a) &lt;m L(b) /* Load → Load */</li>
<li>If L(a) &lt;p S(b) ⇒ L(a) &lt;m S(b) /* Load → Store */</li>
<li>If S(a) &lt;p S(b) ⇒ S(a) &lt;m S(b) /* Store → Store */</li>
<li>If S(a) &lt;p L(b) ⇒ S(a) &lt;m L(b) /* Store → Load */</li>
</ol>
</li>
<li>每一个load得到的值为依global memory order在该load之前写入的值。</li>
</ol>
<p>对于原子的read-modify-write操作（如test-and-set)，要求load和store操作连续，中间不能有其他的内存操作（无论是相同还是不同的地址）。</p>
<img src="/images/A-Primer-on-Memory-Consistency-and-Cache-Coherence-044baf0ff63e42afa375411c9470a616/Untitled.png">
<p>表中定义了SC允许的行为，其中Operation 1在Operation 2之前，X意味着必须遵守program order。</p>
<p>一个SC实现只允许SC执行，这是safety属性(do no harm)，SC实现还有liveness属性(do some good)。</p>
<p>3.6 SC的naive实现</p>
<ul>
<li>
<p>使用单核来执行多线程程序， 在线程切换之前所有pending的内存操作必须完成。</p>
</li>
<li>
<p>使用一组核、内存和内存开关来实现，开关选取一个核来满足其内存访问请求，这定义了memory order &lt;m。</p>
<ul>
<li>该实现中不需要cache或者coherence。</li>
</ul>
  <img src="/images/A-Primer-on-Memory-Consistency-and-Cache-Coherence-044baf0ff63e42afa375411c9470a616/Untitled-1.png">
</li>
</ul>
<p>3.7 带有cache coherence的基本实现，能够并行的执行不冲突的load和store操作</p>
<img src="/images/A-Primer-on-Memory-Consistency-and-Cache-Coherence-044baf0ff63e42afa375411c9470a616/Untitled-2.png">
<p>这个SC实现中</p>
<ul>
<li>充分利用了cache的时延和带宽优势。</li>
<li>和它使用的cache coherence协议有相同的扩展性。</li>
<li>将实现core从实现coherence的复杂度解耦开。</li>
</ul>
<p>3.8 继续优化</p>
<ul>
<li>
<p>Non-Binding Prefetching。对块B的非绑定预取是指向coherent内存系统发请求来改变一个或多个cache中的coherence状态。重要的是，非绑定预取不会修改寄存器的状态或者块B中的数据，对memory consistency model相当于no-op。</p>
</li>
<li>
<p>Speculative Cores。推测执行在分支预测失败时，会无效化之前的操作，称为squashing，squashed的load和store操作看起来像非绑定预取，不影响SC。对store，可能会提前发起GetM预取，但只有store保证提交时才写入cache。</p>
</li>
<li>
<p>Dynamically Scheduled Cores。乱序执行，如将L2提到L1之前执行，有两种方式来检查预测的正确性。</p>
<ul>
<li>在核推测执行完L2，但在提交前，检查是否脱离了cache，监听L2相关的内存地址是否有GetM请求。</li>
<li>在核准备提交load前，重放推测的load，检查结果是否相同。</li>
</ul>
  <aside>
  💡 Flashback to Quiz Question 1: In a system that maintains sequential consistency, a core must issue coherence requests in program order. True or false?
  Answer: False! A core may issue coherence requests in any order.
  </aside>
</li>
<li>
<p>Non-Binding Prefetching in Dynamically Scheduled Cores。非绑定预取不影响SC。</p>
<ul>
<li>SC规定了load和store（看起来）应用到coherent memory的顺序，但没有规定coherent activity的顺序。</li>
</ul>
  <aside>
  💡 Flashback to Quiz Question 2: The memory consistency model specifies the legal orderings of coherence transactions. True or false?
  Answer: False!
  </aside>
</li>
<li>
<p>Multithreading。一个挑战是保证store在对其他核上的线程可见之前，相同核上的T1线程不能读到T2线程写入的值。</p>
</li>
</ul>
<p>3.9 SC下的原子操作</p>
<p>原子的atomic-read-write操作可以如下优化：一个核以M状态获取到cache，然后只需要load和store它的cache块，没有任何的coherence message或者锁总线，只要它直到store之后才服务任何的coherence请求。(个人理解：变成M之后，只要它不响应coherence请求，其他的核就没法得到S或M状态的cache，因此不能读，也不能写。）</p>
<aside>
💡 Flashback to Quiz Question 3: To perform an atomic read-modify-write instruction (e.g., test-and-set), a core must always communicate with the other cores. True or false?
Answer: False!
</aside>
<p>更进一步的优化为推测执行，如果cache的状态已经为S，RMW的load部分可以马上推测执行，同时cache控制器发起修改为M状态。在cache变为M状态后，再执行写部分。使用和前面类似的方式来检测预测失败，即cache是否被弹出。</p>
<h2 id="chap4-total-store-order-and-the-x86-memory-model">Chap4 Total Store Order and the x86 Memory Model</h2>
<p>在cache进入read-write coherence状态之前store可以进入write buffer。write buffer隐藏了store miss的延迟。</p>
<p>如果使用激进的预测SC实现来使得write buffer透明的话，复杂性很高，检测violation和处理mis-speculation的功耗很高。因此出现 了TSO模型。</p>
<p>TSO/X86的形式化定义</p>
<ol>
<li>相比SC会出现Store-Load的reorder，增加了FIFO的write buffer。</li>
<li>Load读到同一地址上一次Store的值。优先是按照program order在之前写入的值（从write buffer读），其次是按照memory order在之前写入的值。</li>
<li>提供了FENCE来保证顺序。
<ol>
<li>If S(a) &lt;p FENCE ⇒ S(a) &lt;m FENCE /* Store → FENCE */</li>
<li>If FENCE &lt;p L(a) ⇒ FENCE &lt;m L(a) /* FENCE → Load */</li>
</ol>
</li>
</ol>
<img src="/images/A-Primer-on-Memory-Consistency-and-Cache-Coherence-044baf0ff63e42afa375411c9470a616/Untitled-3.png">
<p>B意味着对相同地址需要bypassing。</p>
<p>AMD和Interl还没有正式的规范表明是TSO，但是所有的例子都符合TSO。</p>
<img src="/images/A-Primer-on-Memory-Consistency-and-Cache-Coherence-044baf0ff63e42afa375411c9470a616/Untitled-4.png">
<p>在4.4a中</p>
<ul>
<li>Load和Store以&lt;p离开核。</li>
<li>Load要么从write buffer bypass值，要么等待switch。</li>
<li>Store进入FIFO write buffer的尾部，如果满了则stall。</li>
<li>Switch选择某个核时，要么执行Load，要么执行write buffer头部的store。</li>
</ul>
<p>4.4b中，之前讨论的SC实现依然适用。大多数TSO实现都是在SC实现上插入了write buffer。</p>
<p>对多线程的core，一个线程上下文不应该bypass另一个线程上下文的write buffer。可以实现为每个线程上下文的write buffer，或者共享的write buffer加上线程上下文tag。后者更加常见。</p>
<aside>
💡 Flashback to Quiz Question 4: In a TSO system with multithreaded cores, threads may bypass values out of the write buffer, regardless of which thread wrote the value. True or false? 
Answer: False! A thread may bypass values that it has written, but other threads may not see the value until the store is inserted into the memory order.
</aside>
<p>read-modify-write实现。按照TSO定义，RMW的load不能跳过之前的load。如果RMW的load跳过了之前的store，因为RMW是原子的，其store也要跳过之前的store，而TSO是不允许store跳过store的。</p>
<p>RMW需要之前的store有序，即需要排干write buffer。为了保证RMW的store马上在load之后，需要获得read-write的coherence权限。为了保证原子性，在load和store之间不能放弃coherence权限。</p>
<p>更多的优化是可行的。write-buffer在满足下面的条件时不需要排干</p>
<ul>
<li>
<p>在write-buffer中的每个项在cache中有read-write权限，并在RMW提交前保持read-write权限。</p>
</li>
<li>
<p>使用MIPS R1000风格的load speculation检查。</p>
<blockquote>
<p>在cache block弹出时的地址如果和load speculation的地址相同，会使得load和之前的指令都失效。在Load提交时，它一直保持在cache中，值必然相同。</p>
</blockquote>
</li>
</ul>
<p>逻辑上来说，RMW之前的load和store作为一个chunk整体提交。</p>
<p>FENCE的语义是FENCE之前的指令必须排序（应该是&lt;m）在之后的指令之前。TSO下的FENCE不频繁，性能要求不高，在排干write buffer之后再执行load就足够了。</p>
<p>SC是TSO的子集。</p>
<img src="/images/A-Primer-on-Memory-Consistency-and-Cache-Coherence-044baf0ff63e42afa375411c9470a616/Untitled-5.png">
<h2 id="chap5-relaxed-memory-consistency">Chap5 Relaxed Memory Consistency</h2>
<p>5.1 动机</p>
<p>RMO只保持程序员需要的顺序。</p>
<p>如果操作不依赖许多Load和Store之间的顺序，使用relaxing order可以获得更高的性能。</p>
<p>优化的机会包括</p>
<ul>
<li>使用非FIFO的write buffer，来获得更多的写合并。</li>
<li>不需要做复杂的core speculation，本身就允许乱序的load。</li>
<li>通过打开coherence魔盒，来获得更高的性能。允许一组核读到最新的值，而其他的核读到老的值。</li>
</ul>
<h3 id="example-relaxed-consistency-modelxc">eXample relaxed Consistency Model(XC)</h3>
<p>XC不是实际的模型，假定存在global memory order，和不再使用的Alpha, SPARC RMO相同。</p>
<p>XC对相同地址的访问维护TSO规则。</p>
<ul>
<li>相同地址的Load → Load</li>
<li>相同地址的Load → Store</li>
<li>相同地址的Store → Store</li>
</ul>
<p>XC中的Load马上就能看到对自己核的更新（就像TSO的write buffer bypassing)。</p>
<p>XC的形式化定义</p>
<ol>
<li>
<p>所有的核将load, store和FENCE插入&lt;m，并遵循下面的规则</p>
<ul>
<li>If L(a) &lt;p FENCE  ⇒ L(a) &lt;m FENCE                  /* Load → FENCE */</li>
<li>If S(a) &lt;p FENCE  ⇒ S(a) &lt;m FENCE                  /* Store → FENCE */</li>
<li>If FENCE &lt;p FENCE  ⇒ FENCE &lt;m FENCE                  /* FENCE → FENCE */</li>
<li>If FENCE &lt;p L(a)  ⇒ FENCE &lt;m L(a)                  /* FENCE → LOAD */</li>
<li>If FENCE &lt;p S(a)  ⇒ FENCE &lt;m S(a)                  /* FENCE → STORE */</li>
</ul>
</li>
<li>
<p>所有的核将对相同地址的load和store插入&lt;m，并遵循下面的规则</p>
<ul>
<li>If L(a) &lt;p L’(a) ⇒ L(a) &lt;m L’ (a)        /* Load → Load to same address */</li>
<li>If L(a) &lt;p S(a) ⇒ L(a) &lt;m S(a)        /* Load → Store to same address */</li>
<li>If S(a) &lt;p S’(a) ⇒ S(a) &lt;m S’ (a)        /* Store → Store to same address */</li>
</ul>
</li>
<li>
<p>Load得到对相同地址的Store的值。</p>
<p>Value of L(a) = Value of MAX &lt;m {S(a) | S(a) &lt;m L(a) or S(a) &lt;p L(a)} /* Like TSO */</p>
</li>
</ol>
<img src="/images/A-Primer-on-Memory-Consistency-and-Cache-Coherence-044baf0ff63e42afa375411c9470a616/Untitled-6.png">
<ul>
<li>B指对相同地址需要bypassing。</li>
<li>A指对相同地址才保持顺序。</li>
</ul>
<p>实现XC</p>
<img src="/images/A-Primer-on-Memory-Consistency-and-Cache-Coherence-044baf0ff63e42afa375411c9470a616/Untitled-7.png">
<p>相比TSO，加上了reorder unit。</p>
<ul>
<li>Load, Store, FENCE以&lt;p顺序进入reorder的尾部</li>
<li>reorder unit遵循一定规则进行reorder，将操作从尾部移动到头部。FENCE到达头部后被丢弃。</li>
<li>switch选取某个core时，执行reorder头部的store或者load。</li>
</ul>
<p>作者之前预测speculative core会逐渐取代relaxed model，既能保证性能，接口又更加简单，但两方面的原因导致没有发生：厂商的冲量；低功耗的场景做不到高speculative。</p>
<p>XC的原子指令</p>
<p>XC中的RMW不需要draining write buffer，只需要获取到read-write权限，并在load部分和store部分之间不能放手。</p>
<p>TSO中的原子RMW就足以实现锁，而在XC中需要前后加上FENCE。</p>
<img src="/images/A-Primer-on-Memory-Consistency-and-Cache-Coherence-044baf0ff63e42afa375411c9470a616/Untitled-8.png">
<p>XC中的FENCE实现</p>
<ul>
<li>实现SC，将FENCE作为no-op</li>
<li>将FENCE实现为drain之前的内存操作。</li>
<li>不drain，怎么做书里面没讲。</li>
</ul>
<p>上面所有的情况中，FENCE都需要知道FENCE前的操作Xi是否结束了，在某些情况下非常tricky。</p>
<h3 id="sc-for-drfdata-race-free">SC for DRF(data race free)</h3>
<p>用于高阶语言做抽象，除了指定的同步操作需要保持顺序外，其他的操作允许做reorder。SC for DRF概括为下面两条</p>
<ul>
<li>要么有data race，暴露了类似XC的load和store的reordering</li>
<li>要么data race free，执行看起来就像SC。</li>
</ul>
<p>SC for DRF可以让程序员使用SC来论证程序的正确性，而不需要考虑更复杂的XC规则，而且能从XC相比SC的硬件性能提高或操作简化中受益。</p>
<img src="/images/A-Primer-on-Memory-Consistency-and-Cache-Coherence-044baf0ff63e42afa375411c9470a616/Untitled-9.png">
<p>在HLL中只在必要的地方加上同步，如atomic和synchronized，在low-level program根据硬件产生合适的指令。</p>
<p>Java中的内存操作都是SC，C++允许更relaxed的模型。</p>
<aside>
💡 Flashback to Quiz Question 5: A programmer who writes properly synchronized code relative to the high-level language consistency model (e.g,. Java) does not need to consider the architecture’s memory consistency model. True or false?
Answer: It depends. For typical application programmers, the answer is True, because their programs behave as expected (SC is expected). For the programmers of compilers and runtime systems, the answer is False.
</aside>
<p>ARMv7似乎不保证total memory order，ARMv8切换到了提供total memory order的multi-copy atomic memory order。</p>
<blockquote>
<p>write atomicity, store atomicity, multi-copy atomicity。是指一个核的store在逻辑上被其他核同时可见。
write atomicity能够推导出causality，反之不然。</p>
</blockquote>
]]></content:encoded>
    </item>
    
  </channel>
</rss>
